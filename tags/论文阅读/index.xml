<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>论文阅读 on Road to Final</title>
    <link>https://hearecho.github.io/tags/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/</link>
    <description>Recent content in 论文阅读 on Road to Final</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-cn</language>
    <lastBuildDate>Tue, 31 Aug 2021 15:33:49 +0800</lastBuildDate><atom:link href="https://hearecho.github.io/tags/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>HEFT算法 静态调度</title>
      <link>https://hearecho.github.io/post/heft%E7%AE%97%E6%B3%95-%E9%9D%99%E6%80%81%E8%B0%83%E5%BA%A6/</link>
      <pubDate>Tue, 31 Aug 2021 15:33:49 +0800</pubDate>
      
      <guid>https://hearecho.github.io/post/heft%E7%AE%97%E6%B3%95-%E9%9D%99%E6%80%81%E8%B0%83%E5%BA%A6/</guid>
      <description>论文 《Performance-effective and low-complexity task scheduling for heterogeneous computing 》
 本文是异构平台的两种静态调度方法，分别是heft和cpop算法。
 模型符号    符号 意义     $\overline {w_i}$ 任务i的平均执行时间   $w_{i,j}$ 任务i在处理器j上的执行时间   $L$ 处理器通信模块启动时间   $L_m$ 处理器m的通信模块启动时间   $c_{i,k} = L_m + \frac{data_{i,k}}{B_{m,n}}$ 任务i和任务j的通信时间   $B_{m,n}$ 处理器m，n的单位时间通信量   $data_{i,k}$ 任务i和任务j的通信量   $EST(n_i,p_j) = max{avail[j], max_{n_m\in pred(n_i)} (AFT(n_m)+c_{m,j})}$ 任务i在处理器j上的最早启动时间   $EFT(n_i,p_j) = w_{i,j} + EST(n_i,p_j)$ 任务i在处理器j上的最早完成时间   $avail[j]$ 处理器j最早可用时间   $makespan = max{AFT(n_{exit})}$ dag的工作完成时间   $rank_u(n_i) = \overline {w_i} + max_{n_j \in succ(n_i)}(\overline {c_{i,j}}+rank_u(n_j)) $ 作为权重   $rank_d(n_i) = max_{n_j \in pred(ni)} {rankd(n_j) + \overline {w_j} + \overline {c_{j,i}}}$ 作为权重    算法 两个重要指标 $rank_{u}$  $rank_{u}$是从任务ni到出口节点关键路径的长度，是包括任务ni的计算耗时的。对于出口节点$rank_{u}$的值等于它的平均执行时间。</description>
    </item>
    
    <item>
      <title>DEFF算法论文阅读</title>
      <link>https://hearecho.github.io/post/deff/</link>
      <pubDate>Sun, 22 Aug 2021 15:19:32 +0800</pubDate>
      
      <guid>https://hearecho.github.io/post/deff/</guid>
      <description>论文介绍 《Dynamic_scheduling_algorithm_for_parpllel_real_time_jobs_in_heterogeneous_system》
 异构系统中并行实时作业的动态任务调度仍然是一些研究人员正在研究的具有挑战性的问题。但是基于DAG的实时任务调度还没有得到足够的重视。提出了一种基于DAG的实时任务调度模型和一种时间复杂度较低的实时调度算法DEFF。仿真实验表明，该调度模型和调度算法是可行的，在中小型并行作业的情况下，该算法可以获得较高的调度成功率
 模型符号    符号 意义     $V$ 实时任务集合   $E$ 任务之间通信   $dl(v_i)$ 任务$v_i$的截至时间   $cv_i$ 任务$v_i$的计算量   $e_{i,j}=(v_i,v_j)$ 表示任务$v_i,v_j$之间的通信量   $P$ 处理器集合   $p_i$ 拥有本地存储的处理器   $C:V*P \rightarrow R$ 表示不同的计算能力   $w_k$ 表示处理器$p_k$在单位时间内的计算量   $cv_i/w_k$ 表示任务$v_i$在处理器$p_k$上的计算时间   $M:E * P * P \rightarrow R$ 表示异构通信能力。   $w_{km}$ 表示处理器$p_k,p_m$之间单位长度信息的传输时间   $w_{km}*e_{i,j}$ 表示$e_{i,j}$的传输时间   queue-Global Job Queue （GJQ） 全局作业队列，所有到达系统的任务首先都要进入这个队列中，然后再进入中心调度器。进入这个队列的是DAG任务   queue-Task Dispatch Queue (TDQ) 和中心调度器进行交互的，分解之后的dag子任务   Local Scheduling Queue (LSQ) 每个处理器拥有的本地任务队列   $at(p_k)$ 处理器$p_k$的最早空闲时间   $st_k(v_i)$ 实时任务$v_i$的最早开始时间   $ft_k(v_i)$ 映射到处理器$p_k$实时任务$v_i$的最早完成时间    调度算法 定义1  如果映射到处理器$p_k$实时任务$v_i$的最早完成时间$ft_k(v_i)$小于等于任务$v_i$的截至时间$dl(v_i)$，则实时任务$v_i$可以被调度到处理器$p_k$中。</description>
    </item>
    
    <item>
      <title>Surver Dynamic Dag Schedule</title>
      <link>https://hearecho.github.io/post/surver-dynamic-dag-schedule/</link>
      <pubDate>Sun, 22 Aug 2021 09:58:40 +0800</pubDate>
      
      <guid>https://hearecho.github.io/post/surver-dynamic-dag-schedule/</guid>
      <description>动态DAG调度综述  在异构系统中调度的核心问题是：由于异构系统中处理器的性能不尽相同，所以为了获得更高的性能。系统调度需要将应用程序的任务分配给合适的处理器，并对每个资源上的任务执行进行排序。给定一个有向无环图（DAG）建模的应用程序，调度问题处理的是在异构环境中映射每个任务以最小化执行时间（makspan）。
 动态调度基础  动态调度，任务在到达时分配给处理器，调度决策必须在运行时做出。调度决策基于在运行时可能更改的动态参数。在动态调度中，任务可以在运行时重新分配给其他处理器。动态调度相比静态调度灵活且速度更快。由于我们异构系统处理同一个任务的时间是不相同的，所以我们每次调度的时候应该考虑将任务放在最合适的处理器中。
 相关的DAG调度算法 Monte Carlo 算法  Stochastic DAG scheduling using a Monte Carlo approach
该算法使用静态调度方法。主要目的是最大限度地缩短完工时间。该算法避免了适用于任意随机分布的随机变量的复杂计算。阈值用于优化调度。概率分布用于最小化完工时间。
 CBHD 算法  基于集群的复制权重，用于异构系统上任务的高效调度和映射，将程序分解为子任务，同时与其他任务一起工作[12]。该算法将三重聚类算法与HEFT算法相结合，将任务分为相互关联的组，并对每个簇中的任务进行排序，以提高负载均衡调度算法的性能。其主要目标是最小化执行时间，最大化处理器利用率和处理器之间的负载平衡。
 P-HEFT算法  P-HEFT（并行异构最早完成时间）的算法。该算法在不影响最大完工时间的前提下，以很高的效率处理异构集群中的并行任务。该算法的主要目标是最小化具有不同到达时间的作业的最大完工时间和批处理时间，从而在作业执行期间更改分配给作业的处理器(看描述也不是动态算法)
 High Performance and Energy Efficient Task Scheduling Algorithm  该算法关注调度长度和能量/功耗的最小化。该算法分为编译阶段和运行阶段。编译时间阶段有三个阶段，例如级别排序、任务优先级和处理器选择。在运行期间，为了节省能量，该算法将任务从繁忙节点重新调度到理想节点。该算法的性能明显优于传统算法。
该算法为动态调度算法。
 Constrained Earliest Finish Time (CEFT) Algorithm  受约束的最早完成时间。这种新方法是使用受约束关键路径（CCPs）的概念为异构系统提供更好的调度。一旦发现DAG中的CCPs，任务将使用整个CCPs的完成时间进行调度。这种方法有助于以较短的完工时间生成时间表，并且工作复杂度很低。
 Sorted Nodes in Leveled DAG Division (SNLDD) Algorithm  该算法称为高性能任务调度算法。这种类型的算法将DAG划分为不同的级别，每个级别根据计算时间按降序排序，从而减少任务之间的依赖性。静态任务调度适用于处理器数量有限的异构系统。这种类型可能会产生高质量的任务调度。DAG中所有任务的计算时间只计算一次，因此消除了运行时开销。处理器的平滑时间也被最小化，因为DAG被调平并分配给处理器。
 Multi – Queue Balancing Algorithm  在功能单元中引入了调度概念。该算法具有各种类型的功能单元，不使用有限数量的硬件和软件。这种类型的算法称为离线非确定性算法。该算法的主要目标是最小化作业完成时间，根据资源的可用性将任务分配给机器，并最大限度地利用异构系统。每个任务都在其匹配的处理器上执行。也是静态调度算法。</description>
    </item>
    
    <item>
      <title>Runtime_Parallel_Incremental_Scheduling_of_DAGs论文阅读</title>
      <link>https://hearecho.github.io/post/runtime_parallel_incremental_scheduling_of_dags%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/</link>
      <pubDate>Sun, 08 Aug 2021 11:25:01 +0800</pubDate>
      
      <guid>https://hearecho.github.io/post/runtime_parallel_incremental_scheduling_of_dags%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/</guid>
      <description>论文简介 《Runtime Parallel Incremental Scheduling of DAGs》
这篇论文主要是提出一种并行增量的DAG调度方法。主要学习一下这篇论文关于动态调度DAG任务方面的内容。因为之前主要用的最多的静态调度方法就是HEFT与CPOP。所以想通过这篇文章，看是否可以将动态思路运用到HEFT或者CPOP中。本篇论文仍然是针对一个DAG图进行调度。并未给出针对多DAG图的相关思路。
论文出发点 本篇论文出发点是从当前DAG调度算法的缺点出发的，主要列举出五点，分别是：
 因为它们在单处理器机器上运行，所以速度很慢。调度程序可能需要现代工作站数十小时的计算时间来生成1K处理器的调度计划。 它们需要很大的内存空间来存储图形，并且此后无法扩展。例如，要将并行程序调度到1K处理器，数百万个节点的图形可能需要数百MB的内存空间。 获得的计划的质量在很大程度上依赖于对执行时间的准确估计。没有这些信息，复杂的调度算法就无法提供令人满意的性能。 应用程序必须针对不同的问题大小重新编译，因为任务数量和每个任务的估计执行时间随问题大小而变化。 它是静态的，因为编译时必须知道DAG中任务的数量和任务之间的依赖关系。因此，它不能应用于动态问题。  论文概述 静态动态调度系统的区别 在静态系统中，DAG由用户程序生成，并在编译时调度。然后将计划的DAG加载到PEs以执行。在运行时调度系统中，DAG不是一次生成的。相反，它是增量生成的。为此，在编译时生成一种紧凑形式的DAG（紧凑DAG或CDAG）。然后在运行时将其增量扩展到DAG。CDAG的大小与程序大小成正比，而DAG的大小与问题大小或矩阵大小成正比。
增量执行模型 在增量执行模型中，每个系统阶段只调度一个子图。每次生成的子图的大小通常受到可用内存空间的限制。系统调度活动与基础计算工作交替进行。它从一个系统阶段开始，在此阶段仅生成和调度DAG的一部分。然后是用户计算阶段，以执行计划任务。PEs将执行，直到大多数任务完成，并转移到下一个系统阶段，以生成和安排DAG的下一部分
策略决定何时从用户计算阶段转移到下一个系统阶段。当任何PE的任务用完时，都会触发该事件。PE通过向所有其他PE广播暂停信号来启动调度活动。PE在接收到暂停信号后，完成当前任务的执行，并从该用户阶段切换到下一个系统阶段。在下一个系统阶段，将生成DAG的另一部分。新生成的任务与旧任务一起调度。这样，可以容忍由于估算不准确而导致的负载不平衡。然后将计划任务发送给PEs，以开始下一个用户阶段。
并行调度算法 由于动态调度算法，需要实时进行调度，所以我们应该找到，调度时间和任务执行时间之和最短的算法。
ALAP(as-laste-as-possible):一个节点的尽可能晚的时间定义为$T_L(n_i) = T_{critical}-level(n_i)$，其中$T_{critical}$是计算节点和边权重的关键路径长度。$level(n_i)$​是当前节点到最后节点的最长路径的长度，包括当前节点。
PPE:执行调度算法的PE
TPE:执行任务的目标PE
MCP算法  计算每个节点的ALAP时间 按递增的ALAP顺序对节点列表进行排序。通过使用后继节点的最小ALAP时间、后继节点的后继时间等来断开连接 将列表中的第一个节点调度到允许最早开始时间的PE。从列表中删除节点并重复步骤3，直到列表为空。  作者通过使用MCP算法的非插入版本来进一步降低复杂性。它的复杂度是$O(e+nlogn+np)$​​，其中e是边的个数，p是PEs的个数，n是图中的节点数。作者的实验表明，对于粗粒度划分，该算法产生的调度长度最多比原始MCP长3%，但其调度时间减少了一到两个数量级。
水平并行MCP算法（HPMCP） 图形分区后，每个PPE使用MCP调度其分区以生成其子调度。在应用MCP时，我们忽略了分区之间的依赖关系，因此每个分区都可以独立调度。如果一个节点的所有父节点都不是本地节点，则该节点在其分区中被视为入口节点。节点按其ALAP优先级的顺序进行调度。每个PPE从其本地时间0开始调度其分区。然后连接相邻的子调度以形成最终调度。如下图所示：
 对节点进行分区，每个分区分配给一个PPE 每个PPE将MCP算法应用于其分区以生成子调度，忽略节点与其远程父节点之间的边缘。将列表中的第一个节点安排到允许最早启动时间的TPE。从列表中删除节点并重复此计划步骤，直到列表为空。 连接每对相邻的子表。  系统概览 作者提出的运行时系统主要包括DAG图形生成、调度、节点执行、通信处理和增量执行处理模块。
DAG图形生成 在系统阶段k，新扩展的节点和上阶段未执行的节点集。生成的DAG子图$G_k = {S_k,E_k}$​。如果节点$n_i，n_j$​都在节点集合$S_k$​中那么$e_{i,j}$​是$E_k$​中的一条边。如果目标节点不在$S_k$​中，则来自$S_k$​中节点任何传出边缘将成为*future message*。之后子图$G_k$将会被安排到PE中，并在用户阶段k执行。
调度 调度模块将为$S_k$中的每个节点建立从其逻辑ID到其物理ID的映射，该物理ID由目标PE编号和目标PE处的本地ID组成。对于每个在$E_k$中的边$e_{i,j}$，节点$n_i$拥有节点$n_j$的物理ID。因此，当节点i执行完成时，其所有传出消息可以立即定向到其目的地。一旦PPE生成其节点子集，它将使用MCP算法独立地调度这些节点以形成子调度。一个已经被调度的DAG会被加载到TPEs中执行，每个TPE获得一个按执行顺序排序的节点列表（使用本地ID）。
执行 在执行模块中，调度例程负责选择节点并准备执行。在被调度的DAG中，列表中的节点将按顺序执行。分派例程选择列表中的下一个节点并检查其传入消息。当所有传入消息到达后，节点就准备就绪并执行。分派例程为节点的执行分配内存并准备参数。然后调用节点过程。节点执行完成后，通信处理模块处理输出参数。为节点分配的所有内存空间也将被释放。这种消息驱动的宏数据流执行模型可以有效地利用内存。
通信处理 当PE没有准备好执行的节点时，或者在一个节点执行完成和下一个准备好的节点执行开始之间的时间段内，处理消息接收。由于推送方案应用于包含其目的地PE号码以及本地ID的每个传出消息，因此到达的消息可以容易地附加到相应的节点。一旦所有传入消息到达，节点本身就可以执行了。节点执行后，将为每个传出边缘发送一条消息。如果消息只有一个目的地，则将其分类为单播。如果消息具有多个回执，则将其分类为多播。尽管多播消息可以逐个发送到不同的目的地，但它可能需要不可接受的通信时间。通信模块使用多播树进行有效的多播
增量执行处理 接收到暂停消息的每个PE将完成当前节点执行并暂停其当前用户阶段k。在进入系统阶段k+1之前，需要处理尚未执行的剩余节点以及相应的消息，以将其合并到阶段k+1中。在进入阶段k+1之前，必须使节点逻辑ID到其物理ID的当前映射无效，因为物理ID仅对特定阶段有意义。当剩余节点被发送回重新调度时，已经到达这些节点的消息被分离并转换为将来要附加到阻塞队列中的消息，以便延迟这些消息的传递，直到新映射可用于阶段k+1。如果该消息是多播消息，它将被删除，因为多播消息将在以后的每个阶段重新广播。（多播消息是每个阶段都会广播一次，而单播之后发送一次，所以需要进行保存，防止节点未执行，重新分配之后，不能收到消息）</description>
    </item>
    
    <item>
      <title>论文阅读 EDF</title>
      <link>https://hearecho.github.io/post/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-edf/</link>
      <pubDate>Wed, 30 Jun 2021 11:50:15 +0800</pubDate>
      
      <guid>https://hearecho.github.io/post/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-edf/</guid>
      <description>论文阅读 《A Stretching Algorithm for Parallel Real-time DAG Tasks on Multiprocessor Systems》
本篇论文的算法属于静态调度算法，预先知道DAG图，然后根据DAG图转换为MTS。再在MTS的基础上对整个任务进行拉伸。也就是本文提出的全局拉伸算法。
本文的贡献  提出了一种适用于DAG任务模型的拉伸算法。该算法是DAG调度过程的前一步（静态调度）。将并行的DAG转换为独立的舒徐线程，其他无法进行转换，或者转换之后超出时间的则在其他处理器并行执行。 对于在m个相同处理器平台上执行的由n个DAG任务组成的任务集合，作者证明了扩展任务的全局EDF调度具有相同的资源扩充界限:$\frac{3+\sqrt{5}}{2}$，在$n&amp;lt;\varphi*m^{&#39;}$，其中$m^{&#39;}&amp;lt;=m$，是除了主线程之外的其他线程的数量，而$\varphi$是黄金分割率。  文章中参数的含义    参数名 含义     ${t_{i,j} 1&amp;lt;=j&amp;lt;=n_i}$   $G_i$ 子任务之间的依赖关系   $O_i$ DAG任务的偏移量   $D_i$ DAG任务的相对截至时间   $T_i$ 连续任务之间的间隔时间，一般看作$T_i=D_i$   $C_{i,j}$ 单个子任务任务的最坏执行情况所用的时间   $C_i = \sum_{j=1}^{n_i}C_{i,j}$ 单个DAG任务的最坏执行情况所用的时间   $U_i=\frac{C_i}{T_i}$ 利用率，最坏运行情况在限制时间内多少   $Li$ DAG图中所有路径中执行时间最长的路径所用的时间   $Sl_i = D_i-L_i$ 执行最长路径之后剩余的时间。   $S_i$ 转换为MTS形式之后，段的总数。   $e_{i,j}$ 每个段的最长执行时间，按这个段中所有子任务最短的计算。   $m_{i,j}$ 每个段中任务的数量   $MTS L_i = \sum_{j=1}^{s_i}e_{i,j}$ MTS模式下的关键路径的长度   $MTSC_i = \sum_{j=1}^{s_i}m_{i,j}*e_{i,j}$ MTS模式下的最坏情况执行时间   $ f_i = \frac{Sl_i}{C_i-L_i}=\frac{D_i-L_i}{C_i-L_i}&amp;lt;=\frac{D_i}{C_i}&amp;lt;1 $ 分发参数   $f_{i,j} = f_i*(m_{i,j}-1)$ 要添加到主线程的段$S_{i,j}$中的线程数   $D_{i,j} = (1+f_{i,j})*e_{i,j}$ 每段$S_{i,j}$的中间截止日期$D_{i,j}$   $O_{i,j}=\sum_{k=1}^{j-1}D_{i,k}$ 每个段的偏移量    任务模型 文章提出的任务模型就是DAG集合，其中每个DAG任务使用$({t_{i,j}|1&amp;lt;=j&amp;lt;=n_i},G_i,O_i,D_i)$来进行表示，其中$t_{i,j}$表示任务$T_i$的每个子任务，而$G_i$表示各个子任务之间的依赖关系，$O_i$表示整个任务的偏移量，而$D_i$表示任务的相对截至时间。</description>
    </item>
    
    <item>
      <title>论文阅读 DAG</title>
      <link>https://hearecho.github.io/post/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-dag/</link>
      <pubDate>Fri, 25 Jun 2021 13:49:02 +0800</pubDate>
      
      <guid>https://hearecho.github.io/post/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-dag/</guid>
      <description>论文简介 《A new DAG based dynamic task scheduling algorithm (DYTAS) for multiprocessor systems》
论文提出一种基于有向无环图（DAG）的动态任务调度算法。关注点主要是通过多处理系统，进行并行处理任务。主要关注点在于多处理器系统，并行。在多处理器系统中实现高性能是调度并行任务的关键因素。而动态任务调度的目标是将并行任务映射到多处理器上，并对执行顺序进行排序。
本文旨在建立一个基于DAGs的动态调度模型。在该模型中，一个被分配的处理器称为中心调度器，负责动态地调度任务。在提出的动态调度模型的基础上，提出了一种新的动态调度算法。该算法在仿真环境下进行了实验，实验结果表明，所提出的调度算法是一种有效的动态调度算法，具有更好的性能。
 我们常说的对于有向无环图最短执行时间的拓扑排序算法是在单处理器上进行运行的，任务是按照排序好的序列进行执行。
 DAG介绍 有向无环图(DAG) G = (V, E)，其中V是v个节点/顶点的集合，E是e个有向边的集合。边缘的源节点称为父节点，而汇聚节点称为子节点。没有父节点的节点称为入口节点，没有子节点的节点称为出口节点。
相关工作 很多动态调度算法是为了支持实时系统进行设计的。实时系统是指系统的性能不仅取决与逻辑计算结果，而且还取决于结果产生的时间。
调度算法分为静态调度算法和动态调度算法。
 静态调度算法：任务的分配是离线进行的，即在实时任务正式在处理机上调度执行前，先把任务在处理机上的分配和调度时间安排好,在任务正式开始执行后按照预先的调度方案执行。这种调度方法主要用于周期任务的调度，它的优点在于能够预先安排好调动，减少任务调度过程中的开销;而缺点在于缺乏灵活性，在实际的调度中不能够及时地根据系统资源和任务的执行情况进行及时的调整。 动态调度算法：在实时系统中，很多任务并非都以周期方式在处理机上进行调度，更多任务，特别是非周期任务都是随机到达系统并动态调度执行的。在动态调度方法中，任务的分派和可调度性测试都是在系统运行时在线进行的。这种情况下，可调度性测试实际上变成了一种接受测试(acceptance test), 测试动态到达任务的截止期是否会被保证，如果无法保证任务的截止期，任务将被拒绝调度。可以看出，动态调度与静态调度相比有更好的灵活性，然后由于可调度性测试需要在线进行，它的调度算法的复杂度不能太高，并且由 于无法保证是否可以被调度，算法的可预测性(predictability)很差。也就是说动态调度算法主要算法是在线测试预估任务是否可以满足。  系统模型 负载模型 并行任务采用DAG建模。非实时DAG[7]定义为：G=（V，E），其中V是一组v个节点，E是一组w条有向边。DAG中的一个节点表示一个任务，而这个任务又是一组指令，这些指令必须在同一个处理器中顺序执行而不被抢占。节点ni的权重称为计算成本，用w（vi）表示。DAG中的边，每个边用（vi，vj）表示，对应于节点之间的通信消息和优先约束。边的权重称为边的通信开销，用c（vi，vj）表示。
我们的系统看作有一组处理器组成，P={P1，P2，P3，…Pm}，其中Pi表示具有本地存储器的处理器。处理器之间是也是具有通信开销的。
调度器模型 如下图所示，描述的是一个同构环境中一个新的非实时调度器模型。当所有并行任务到达一个被指定的中央调度器时，他将进入一个称为初始任务队列（ITQ）的队列，等待被调度；除了ITQ之外，还管理着两个队列：调度任务队列（DTQ）和完成任务队列（CTQ）。封装在调度器中的调度算法开始与ITQ一起工作。中央调度器负责调度DTQ中的每个就绪任务。一旦调度算法启动，所有的任务都会根据其依赖的任务进行安排。在安排任务之后，调度器将任务安排到单个处理器任务队列（PTQ）。处理器将在自己的PTQ中通过同时检查CTQ中的依赖任务结果来完成任务。如果CTQ没有利用其相关任务的结果，则PTQi应指向下一个PTQi+1、PTQi+2、…PTQn、PTQ1、…PTQi-1以确定合适的任务，并将该任务迁移到PTQi。在PTQi变空之前，调度算法应停止工作。Processor Status Window（PSW）显示处于运行状态和空闲状态的每个处理器的状态。
动态调度算法-DYTAS 基于上述的调度模型，提出了一种新的动态调度算法。ITQ中的任务是通过依赖关系进行调度的。该算法首先对于ITQ中的前面的任务进行调度，并将其映射到处理器上。而在静态调度算法中，由于DAG的数据是预先知道的，所以任务是按一定的优先级排序的。但是，本文提出的动态调度算法不同于静态调度算法，它在运行时迁移任务。
DYTAS算法的核心是处理器的选择策略，也就是对于任务的迁徙。主要取决于如何选择任务映射到的处理器，即使任务被调度得更早。
当从PTQ集合中中选择处理器来执行特定任务时，必须考虑两个时间索引：
 处理器Pi的最早空闲时间 处理器Pi上任务vi的最早开始时间。  在所提出的调度模型中，ITQ中的并行任务和就绪任务都在处理器的PTQ中。即使ITQ和DTQ位于中央调度器上，实际执行映射任务的处理器也与调度器分离并放置在PTQi处。同时，调度过程和执行过程是并行的。因此，调度器和工作处理器之间是同步的。
 该论文算法有点问题，没有讲清楚部分参数的含义。给出的cc参数不知道是什么意思。不知道为啥引用还那么多。
 算法简单解释 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42  Procedure DYTAS # 这个部分是对整个任务进行拓扑排序 dtq[ ] = SORT[Ti , Tj] l = 0; # 将排序好的任务放置在各个不同ptq也就是处理器本地存储队列 while (dtq[ ] is not empty) do for i = 1 to n ptqi = dtq [l] l = l + 1 end for; end while; for each processor Pk in processor group do # 对每个处理器状态进行检查，如果处理器在运行，则选择下一个处理器队列 while (Pk is in running state) skip and select the next ptqk+1 end while Pk = ptqk[j] # 如果这个任务的前置任务已经完成，并且有处理器空闲，则执行任务 if (dependent task of ptqk[j] is in ctq) TASK(ptqk[ ],Pk , j, ctq, cpk, CTj) else # 否则的话，就是将指针指向下一个ptq队列判断，下一个队列同样位置上的任务是否可以执行。算法的关键就在这个部分 # 关键在于在执行的时间迁移任务。 do move the pointer to the next ptq if (dependent task of ptqk[j] is in ctq) TASK(ptqk[ ],Pk , j, ctq, cpk, CTj) exit do endif while(checking with all ptq’s once) endif end for end DYTAS Procedure for TASK # 任务执行 procedure TASK(ptqk[ ],Pk,j,ctq,cpk,CTj) do Tj with Pk remove Tj from ptqk insert Tj in ctq cpk = cpk + Ctj end TASK   实验 实验数据  cp是任务执行时间，cc不清楚是什么，也没说。</description>
    </item>
    
  </channel>
</rss>
